{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROJETO 1 - CLASSIFICADOR DE SENTIMENTO DO FILME JOKER\n",
    "__________________________________________________________________________________________________________________\n",
    "\n",
    "### Alunos:\n",
    "\n",
    "Nome: Beatriz Cabral Fernandes \n",
    "\n",
    "Nome: Eduardo Ancona Mateus \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. INTRODUÇÃO \n",
    "\n",
    "A proposta desse projeto é desenvolver um classificador que irá analisar como o público está reagindo ao premiado filme ***Joker***, do diretor *Todd Phillips*. Para isso, será utilizado como método o famoso algoritmo de Naive-Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. DESENVOLVIMENTO E METODOLOGIA\n",
    "\n",
    "A fim de simplificar a explicação do processo de desenvolvimento do projeto, ele será dividido em 6 etapas\n",
    "\n",
    "### ETAPA 1 - Preparando o ambiente no Jupyter\n",
    "\n",
    "Nessa etapa, serão baixadas e importadas todas as bibliotecas relevantes para o código, bem como implementadas todas as funções a serem utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy\n",
    "\n",
    "#Importando as bibliotecas\n",
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle\n",
    "from IPython.display import Image\n",
    "import re\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "\n",
    "#Repositório com as stopwords em portugues https://gist.github.com/alopes/5358189\n",
    "#leitura de arquivo de texto com stopwords e outras palavra que nao convem ao projeto do dicionario portugues\n",
    "with open('stopwords.txt','r') as arquivo:\n",
    "    stopwords = arquivo.readlines()\n",
    "#aqui é criada uma lista com as stopwords\n",
    "stopwords = '\\n'.join(stopwords).split()\n",
    "\n",
    "\n",
    "#criando funcao de limpeza de caracteres\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Função de limpeza muito simples que troca alguns sinais básicos por espaços\n",
    "    \"\"\"\n",
    "    #import string\n",
    "    http = re.sub(r\"http\\S+\", \"\", text)\n",
    "    mention = re.sub(\"@[A-Za-z0-9]+\",\"\", http)\n",
    "    punctuation = '[! - . : ? ; / _ # ) ( , \\ \" = ー — % « - @ -]' # Note que os sinais [] são delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', mention)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETAPA 2 - Autenticando no Twitter\n",
    "\n",
    "Conta: `@datascience_dudle`\n",
    "\n",
    "\n",
    "Nessa etapa será feita a autenticação no twitter, e posteriormente a coleta de tweets a partir de uma palavra chave. O código pode ser observado no arquivo [Projeto1_Obtenção_dos_tweets.ipynb](http://localhost:8888/notebooks/2%20Semestre%20-%20DP/CDADOS/P1_Cdados_BW/Projeto1_Obten%C3%A7%C3%A3o_dos_tweets.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________\n",
    "\n",
    "### ETAPA 3 - Escolha de um produto e coleta das mensagens\n",
    "\n",
    "No arquivo `Projeto1_Obtenção_dos_tweets.ipynb` foram coletados tweets relacionados ao filme ***Joker*** e salvos em na planilha do excel `Joker.xlsx`. Ao coletar os tweets com essa keyword, obtivemos 901 tweets para treinamento e 300 para teste. A seguir foi feita a leitura dos arquivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazendo a leitura da planilha de treinamento\n",
    "excel = pd.read_excel('Joker.xlsx', sheet_name='Treinamento')\n",
    "excel_teste = pd.read_excel('Joker.xlsx', sheet_name='Teste')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_teste.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETAPA 4 - Classificação manual dos tweets\n",
    "\n",
    "Vale ressaltar que o foco desse estudo é analisar o sentimento dos tweets relacionados ao premiado filme ***Joker***.\n",
    "Desta forma, foram previamente estabelecidas 5 categorias para a classificação das mensagens:\n",
    "\n",
    "* `P` - ***Crítica positiva*** – se a mensagem transmitida é uma crítica positiva;\n",
    "* `N` - ***Crítica negativa*** – se a mensagem transmitida é uma crítica negativa;\n",
    "* `I` - ***Irrelevante*** – se a mensagem transmitida estiver no contexto proposto, mas não for relevante para análise;\n",
    "* `R` - ***Reação*** - se a mensagem transmitida trata-se de uma reação ou emoção em relação ao filme ou a uma cena;\n",
    "* `F` - ***Fora do contexto*** - se a mensagem transmitida esta fora do contexto proposto.\n",
    "\n",
    "\n",
    "Estabelecidas as categorias e selecionados os tweets, foi feita a leitura da base de treinamento, na qual as mensagens foram qualificadas manualmente no excel de acordo com a categoria mais adequada, bem como da base de teste. Conforme mostra a tabela a seguir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel.loc[:,'Etiquetas'] = excel['Etiquetas'].astype('category')\n",
    "excel.Etiquetas.cat.categories = ['P','N','I','R','F']\n",
    "excel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grafico para observar a distribuição das categorias P,N,I,R,F\n",
    "\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "t1 = pd.Series(excel.Etiquetas).value_counts(True).sort_index()\n",
    "t1.plot(kind='bar')\n",
    "plt.title('F.rel por categoria base de Treinamento')\n",
    "plt.ylabel('Frequência Relativa')\n",
    "plt.xlabel('Categorias')\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "t2 = pd.Series(excel_teste.Etiquetas).value_counts(True).sort_index()\n",
    "t2.plot(kind='bar')\n",
    "plt.title('F.rel por categoria base de Teste')\n",
    "plt.ylabel('Frequência Relativa')\n",
    "plt.xlabel('Categorias')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acima, observa-se um número de tweets da categoria F muito grande em detrimento do resto das categorias. Por conta disso, vamos primeiro classificar os tweets em 2 principais categorias: como *Dentro do contexto (soma das categorias P,N,R e I)* ou *Fora do contexto (categoria F)*, a fim de minimizar o enviesamento do classificador e separar as mensagens consideradas \"úteis\" para nossa pesquisa. De maneira que neste primeiro momento temos estabelecidas:\n",
    "* `D` - ***Dentro do contexto*** - se a mensagem transmitida esta dentro do contexto proposto;\n",
    "* `F` - ***Fora do contexto*** - se a mensagem transmitida esta fora do contexto proposto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel1 = excel.apply(pd.Series.replace, to_replace=['P','N','I', 'R'] , value='D')\n",
    "excel_teste.loc[:,'Etiquetas'] = excel_teste['Etiquetas'].astype('category')\n",
    "excel_teste.Etiquetas.cat.categories = ['P','N','I','R','F']\n",
    "excel_teste1 = excel_teste.apply(pd.Series.replace, to_replace=['P','N','I', 'R'] , value='D')\n",
    "excel1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "t3 = pd.Series(excel1.Etiquetas).value_counts(True).sort_index()\n",
    "t3.plot(kind='bar')\n",
    "plt.title('F.rel por categoria base de Treinamento')\n",
    "plt.ylabel('Frequência Relativa')\n",
    "plt.xlabel('Categorias')\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "t4 = pd.Series(excel_teste1.Etiquetas).value_counts(True).sort_index()\n",
    "t4.plot(kind='bar')\n",
    "plt.title('F.rel por categoria base de Teste')\n",
    "plt.ylabel('Frequência Relativa')\n",
    "plt.xlabel('Categorias')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No gráfico acima, pode-se observar a distribuição dos tweets entre as duas categorias estabelecidas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETAPA 5 - Montando o Classificador Naive-Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breve explicação de *Naive Bayes*\n",
    "O algoritmo de *Naive Bayes* é um classificador probabilístico baseado no teorema de Bayes, utilizado no processo de machine learning. O algoritmo supõe que uma característica independe da outra para acontecer, ou seja, mesmo na presença de uma característica particular em uma classe, isso não afeta na probabilidade de qualquer característica ocorrer. O teorema de bayes é escrito da seguinte forma:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/bayes.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $P(A)$ - Probabilidade a priori\n",
    "* $P(B)$ - Probilidade Total\n",
    "* $P(A|B)$ - posteriori\n",
    "* $P(B|A)$ - verossimilhanca\n",
    "\n",
    "\n",
    "Esse método será utilizado no projeto, uma vez que permite calcular, por exemplo, a probabilidade de uma mensagem receber diferentes classificações dado um tweet, assumindo que as palavras nele não tem nenhuma relação entre si.\n",
    "\n",
    "A partir do nosso modelo, poderíamos reescrever o teorema de bayes da seguinte forma:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $P(C|P) = \\frac{P(P|C).P(C)}{P(P)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A variável C é a classe variável que representa a categoria de um tweet, a partir das condições estabelecidas (probabilidade de ocorrência de uma palavra dada as condições). A variável P representa as palavras ocorridas nos tweets.\n",
    "\n",
    "\n",
    "P pode ser:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/bayes2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Substituindo P por cada uma das possíveis palavras, temos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/bayes3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse momento queremos classificar se um tweet está dentro ou fora do contexto do filme Joker. Para tanto é necessário analisar analisar as probabilidades.\n",
    "\n",
    "\n",
    "Ou seja, precisa decidir se:\n",
    "\n",
    "## $P(Dentro do contexto|frase) > P(Fora do contexto|frase)$\n",
    "\n",
    "\n",
    "\n",
    "Utilizando o teorema de Bayes, temos:\n",
    "\n",
    "## $P(D|frase) = \\frac{P(frase|D)P(D)}{P(frase)}$\n",
    "\n",
    "e que:\n",
    "\n",
    "## $P(F|frase) = \\frac{P(frase|F)P(F)}{P(frase)}$\n",
    "\n",
    "\n",
    "\n",
    "Para implementar esse algoritmo, uma nova tabela deve ser criada com as palavras e suas respectivas frequências relativas em cada uma das categorias. Porém antes disso, deverá ser feita uma limpeza das mensagens, removendo pontuações e caracteres que não convém a análise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando categorias do dataset\n",
    "list(excel1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Juntando todos os tweets da base de treinamento\n",
    "texto_completo = cleanup(' '.join(excel1.Treinamento)).split()\n",
    "texto_limpo = [word for word in texto_completo if word not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "palavras_total = pd.Series(texto_limpo).value_counts() #lista com todas as palavras da base de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Número de palavras diferentes na base de treinamento inteira:', len(palavras_total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fazendo uma breve análise dos termos mais frequentes, observa-se que alguns deles não são significantes para a nossa análise, e portanto deve-se ser feita a limpeza para nao prejudicar o resultado/performance. Exemplo:\n",
    "- https \n",
    "- links e mencoes\n",
    "- -\n",
    "- rt\n",
    "- /\n",
    "- @\n",
    "\n",
    "Além disso,foi feita uma limpeza das stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo a probabilidade de cada uma das categorias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "t3 = pd.Series(excel1.Etiquetas).value_counts(True).sort_index()\n",
    "t3.plot(kind='bar')\n",
    "plt.title('F.rel por categoria base de Treinamento')\n",
    "plt.ylabel('Frequência Relativa')\n",
    "plt.xlabel('Categorias')\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "t4 = pd.Series(excel_teste1.Etiquetas).value_counts(True).sort_index()\n",
    "t4.plot(kind='bar')\n",
    "plt.title('F.rel por categoria base de Teste')\n",
    "plt.ylabel('Frequência Relativa')\n",
    "plt.xlabel('Categorias')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_d = t3.D\n",
    "prob_f = t3.F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui, utilizaremos a funcao `Frequencia(n,excel,texto_limpo)` para além de limpar a base, calcular as frequencias de cada uma das categorias e suas respectivas probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Frequencia(n,excel,texto_limpo):\n",
    "    excel = excel\n",
    "    texto_limpo = texto_limpo\n",
    "    texto_completo_n = cleanup(' '.join(excel[excel.Etiquetas==n].Treinamento)).split() #y é uma lista com todas as palavras de cada categoria\n",
    "    texto_limpo_n = [word for word in texto_completo_n if word not in stopwords]\n",
    "    f_rel = pd.Series(texto_limpo_n).value_counts(True)\n",
    "    f_abs = pd.Series(texto_limpo_n).value_counts()\n",
    "    #prob = len(texto_limpo_n)/len(texto_limpo)\n",
    "    return texto_limpo_n,f_rel,f_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d, rel_d, abs_d = Frequencia('D',excel1,texto_limpo)\n",
    "f, rel_f, abs_f = Frequencia('F',excel1,texto_limpo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Número de palavras diferentes na base de treinamento inteira:', len(rel_d+rel_f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para calcular as probabilidades dos tweets dado as categorias, elaboramos a funcao `calcula_prob(n,excel_teste,excel,texto_limpo)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcula_prob(n,excel_teste,excel,texto_limpo, prob):\n",
    "    excel = excel\n",
    "    prob = prob\n",
    "    excel_teste = excel_teste\n",
    "    texto_limpo = texto_limpo\n",
    "    alpha = 1\n",
    "    y,f_rel,f_abs = Frequencia(n,excel,texto_limpo)\n",
    "    probTweetDadoN = []\n",
    "    probNDadoTweet = []\n",
    "    for t in excel_teste.Treinamento: #teste aq pq vou classificar pra depois comparar\n",
    "        PTweetDadoN = 1 #para funcionar o loop que vai multiplicar todas as prob de cada palavra dado a cat\n",
    "        tweet = cleanup(t).split()\n",
    "        tweet_limpo = [word for word in tweet if word not in stopwords]\n",
    "        num_pal_tot_cat = sum(f_abs)#numero de palavras total na categoria n \n",
    "        num_pal_pos = len(rel_d+rel_f) #numero de palavras possiveis na base de treinamento inteira\n",
    "        for p in tweet_limpo:\n",
    "            if p in f_rel:\n",
    "                f_abs_cat = f_abs[p] # quantas vezes a palavra aparece no treino\n",
    "            else: # se a palavra nao tiver na base de treino freq abs é igual a zero\n",
    "                f_abs_cat = 0\n",
    "            PPalavraDadoN = (alpha+f_abs_cat)/(num_pal_pos+num_pal_tot_cat) #probabilidade da palavra dado a categoria #elevei a 2 para as probabilidades nao ficarem mt pequenas\n",
    "            PTweetDadoN = PTweetDadoN * PPalavraDadoN\n",
    "        PNDadoTweet = prob*PTweetDadoN\n",
    "        probTweetDadoN.append(PTweetDadoN) #add a probabilidade de cada tweet dado determinada categoria. \n",
    "        probNDadoTweet.append(PNDadoTweet)#Como estamos analisando uma mesma coluna, o len da lista de ambas as categorias vai ser igual, é tranquilo fazer uma lista\n",
    "    return probTweetDadoN, probNDadoTweet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probTweetDadoD, probDDadoTweet= calcula_prob('D',excel_teste1,excel1,texto_limpo, prob_d)\n",
    "probTweetDadoF, probFDadoTweet = calcula_prob('F',excel_teste1,excel1,texto_limpo, prob_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tenho uma lista com a probabilidade de cada tweet pra cada categoria, logo probDDadoTweet[i] é correspondente a probFDadoTweet[i]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_tweet = []\n",
    "for i in range(len(excel_teste1)):\n",
    "    if probDDadoTweet[i]>probFDadoTweet[i]:\n",
    "        class_tweet.append('D')\n",
    "    else:\n",
    "        class_tweet.append('F')\n",
    "\n",
    "\n",
    "excel_teste1['class_auto'] = class_tweet\n",
    "excel_teste1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETAPA 6 - Verificando a performance do classificador\n",
    "\n",
    "\n",
    "Nesta etapa, iremos verificar a acurácia do nosso classificador. No gráfico a seguir é possível observar como se comporta a classificacao do nosso classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct1 = pd.Series(excel_teste1.class_auto).value_counts(True).sort_index()\n",
    "ct1.plot(kind='bar')\n",
    "plt.ylabel('Frequência Relativa')\n",
    "plt.xlabel('Categorias')\n",
    "plt.show()\n",
    "ct1.to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Uma classificacao correta quer dizer que a categoria definida manualmente é igual a categoria definida pelo nosso classificador. Sendo assim, ao fazer um cruzamento das variáveis etiquetas e class_auto, obtemos a seguinte tabela: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = pd.crosstab(excel_teste1.Etiquetas, excel_teste1.class_auto)\n",
    "ct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fazendo uma análise dela, é possivel calcular o numero de acertos e erros do classificador. Sendo que \n",
    "- quando class_auto = Etiquetas - significa que ele acertou\n",
    "- quando class_auto diferente de Etiquetas - significa que ele errou\n",
    "\n",
    "\n",
    "Logo:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acertos = ct.D['D'] + ct.F['F']\n",
    "erros = ct.D['F'] + ct.F['D']\n",
    "erros, acertos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acuracia = acertos*100/(erros+acertos)\n",
    "print('Acurácia do classificador: {0}%'.format(acuracia.round(3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir do resultado obtido, obeserva-se uma eficiência muito boa para detectar tweets da categoria 'D', em detrimento da categoria 'F'.\n",
    "\n",
    "A seguir, vamos voltar ao objetivo inicial do projeto que era analisar como o público do filme Joker estava reagindo ao filme nas redes sociais. ou seja, vamos calcular a probabilidade do tweet ser P,N,I ou R dentre os tweets que estão dentro do contexto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#criando um df apenas com as categorias dentro do contexto do filme\n",
    "excel_d = excel[(excel.Etiquetas=='P') | (excel.Etiquetas=='N') | (excel.Etiquetas=='I') | (excel.Etiquetas=='R')]\n",
    "excel_teste_d = excel_teste[(excel_teste.Etiquetas=='P') | (excel_teste.Etiquetas=='N') | (excel_teste.Etiquetas=='I') | (excel_teste.Etiquetas=='R')]\n",
    "excel_d.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No gráfico a seguir, pode-se analisar como é distribuida a ocorrencia de cada uma das categorias dentro do contexto. Observa-se uma maior ocorrência de tweets irrelevantes e uma menor ocorrencia de tweets negativos, tanto na base de treinamento, quanto na base de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "t3 = pd.Series(excel_d.Etiquetas).value_counts(True).sort_index()\n",
    "t3.plot(kind='bar')\n",
    "plt.title('F.rel por categoria base de Treinamento')\n",
    "plt.ylabel('Frequência Relativa')\n",
    "plt.xlabel('Categorias')\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "t4 = pd.Series(excel_teste_d.Etiquetas).value_counts(True).sort_index()\n",
    "t4.plot(kind='bar')\n",
    "plt.title('F.rel por categoria base de Teste')\n",
    "plt.ylabel('Frequência Relativa')\n",
    "plt.xlabel('Categorias')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_p = t3.P\n",
    "prob_n = t3.N\n",
    "prob_i = t3.I\n",
    "prob_r = t3.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_completo_d = cleanup(' '.join(excel_d.Treinamento)).split()\n",
    "texto_limpo_d = [word for word in texto_completo_d if word not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, rel_p, abs_p = Frequencia('P',excel_d,texto_limpo_d)\n",
    "n, rel_n, abs_n = Frequencia('N',excel_d,texto_limpo_d)\n",
    "i, rel_i, abs_i = Frequencia('I',excel_d,texto_limpo_d)\n",
    "r, rel_r, abs_r = Frequencia('R',excel_d,texto_limpo_d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probTweetDadoP, probPDadoTweet= calcula_prob('P',excel_teste_d,excel_d,texto_limpo_d, prob_p)\n",
    "probTweetDadoN, probNDadoTweet = calcula_prob('N',excel_teste_d,excel_d,texto_limpo_d, prob_n)\n",
    "probTweetDadoI, probIDadoTweet= calcula_prob('I',excel_teste_d,excel_d,texto_limpo_d, prob_i)\n",
    "probTweetDadoR, probRDadoTweet = calcula_prob('R',excel_teste_d,excel_d,texto_limpo_d, prob_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_tweet_d = []\n",
    "for i in range(len(excel_teste_d)):\n",
    "    maior = probPDadoTweet[i]\n",
    "    class_tweet_d.append('P')\n",
    "    if maior < probNDadoTweet[i]:\n",
    "        maior = probNDadoTweet[i]\n",
    "        class_tweet_d[i] = 'N'\n",
    "    if maior < probIDadoTweet[i]:\n",
    "        maior = probIDadoTweet[i]\n",
    "        class_tweet_d[i] = 'I'\n",
    "    if maior < probRDadoTweet[i]:\n",
    "        maior = probRDadoTweet[i]\n",
    "        class_tweet_d[i] = 'R'\n",
    "    \n",
    "    \n",
    "excel_teste_d['class_auto'] = class_tweet_d\n",
    "excel_teste_d.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct2 = pd.Series(excel_teste_d.class_auto).value_counts(True).sort_index()\n",
    "ct2.plot(kind='bar')\n",
    "plt.ylabel('Frequência Relativa')\n",
    "plt.xlabel('Categorias')\n",
    "plt.show()\n",
    "ct2.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ct_d = pd.crosstab(excel_teste_d.Etiquetas, excel_teste_d.class_auto)\n",
    "ct_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acertos_d = ct_d.P['P'] + ct_d.I['I'] + ct_d.R['R']#n tem n pq n foi class nenhum commo neg\n",
    "acuracia_d = acertos_d*100/len(class_tweet_d)\n",
    "print('Acurácia do classificador: {0}%'.format(acuracia_d.round(3)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observa-se uma baixa acurácia deste segundo classificador. Isso pode ser explicado pelo pequeno tamanho amostral, ou até mesmo pela desproporcionalidade entre uma categoria e outra, que pode gerar certo enviesamento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONCLUSÃO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após feita toda a analise sobre nosso classificador, vimos que ele tem uma acurácia baixa (menos de 50% de acerto), para o classificador ler e definir qual a classe que estava tivemos que definir oque eram as classes, assim definimos que oque estivesse dentro do contexto fosse qualquer twitte falando sobre o filme (não se importando se era um twitte bom ou ruim) e oque estivesse fora do contexto todo o resto.Após feito isso tivemos que definir oque era irrelevante que estava dentro de fora do contexto e oque eram os resto da classes que estavam na classificação de dentro do contexto (no caso as classes critica positiva, critica negativa e reação sobre o filme.\n",
    "\n",
    "Treinamos nosso programa com uma série de palavras para que ele conseguisse definir aquele twitte como as classificações que escolhemos, depois de treinado vimos como ele se comportava e fomos fazendo alguns acertos com as palavras que apareciam mais vezes nos twittes de cada \n",
    "\n",
    "Com isso conseguimos aperfeiçoar ele e ter uma resposta maior, porém ainda ocorrem alguns equivocos pois muita gente dentro do twitter usa o nome como joker ou coringa e isso acabou confundindo o classficador, se pudessemos definir oque era nome e o que era nome do filme em si acabariamos tendo uma acuracia maior.\n",
    "\n",
    "O nosso plano para termos uma ideia de quais twittes são bons e quais são ruins precisariamos tentar uma forma de definir as pessoas que são chamadas de Joker, ou de coringa, e que não estão marcadas com o \"@\" do nome deles, para isso teriamos que ter acesso à algum tipo de machine learning que conseguisse aprender com as alternativas que ele erra, por isso precisariamos de aprender esse tipo de programação e implementa-lo dentro do nosso classificador, fazendo com que assim o classificador ficasse cada vez melhor cada vez que classificar um twitte e errar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BIBLIOGRAFIA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://towardsdatascience.com/naive-bayes-classifier-explained-50f9723571ed\n",
    "- https://stackoverflow.com/questions/24399820/expression-to-remove-url-links-from-twitter-tweet/24399874\n",
    "- https://stackoverflow.com/questions/54733828/remove-twitter-mentions-from-pandas-column\n",
    "- https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/\n",
    "- https://towardsdatascience.com/naive-bayes-classifier-explained-50f9723571ed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

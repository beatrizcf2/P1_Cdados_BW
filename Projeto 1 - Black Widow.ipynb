{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROJETO 1 - CLASSIFICADOR DE SENTIMENTO DO FILME JOKER\n",
    "__________________________________________________________________________________________________________________\n",
    "\n",
    "### Alunos:\n",
    "\n",
    "Nome: Beatriz Cabral Fernandes \n",
    "\n",
    "Nome: Eduardo Ancona Mateus \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. INTRODUÇÃO \n",
    "\n",
    "A proposta desse projeto é desenvolver um classificador que irá analisar como o público está reagindo ao premiado filme ***Joker***, do diretor *Todd Phillips*. Para isso, será utilizado como método o famoso algoritmo de Naive-Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. DESENVOLVIMENTO E METODOLOGIA\n",
    "\n",
    "A fim de simplificar a explicação do processo de desenvolvimento do projeto, ele será dividido em X etapas\n",
    "\n",
    "### ETAPA 1 - Preparando o ambiente no Jupyter\n",
    "\n",
    "Nessa etapa, serão baixadas e importadas todas as bibliotecas relevantes para o código, bem como implementadas todas as funções a serem utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy\n",
    "\n",
    "#Importando as bibliotecas\n",
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle\n",
    "from IPython.display import Image\n",
    "import re\n",
    "\n",
    "#criando funcao de limpeza de caracteres\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Função de limpeza muito simples que troca alguns sinais básicos por espaços\n",
    "    \"\"\"\n",
    "    #import string\n",
    "    punctuation = '[!-.:?;]' # Note que os sinais [] são delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed\n",
    "\n",
    "# Fazendo a leitura da planilha de treinamento\n",
    "excel = pd.read_excel('Joker.xlsx', sheet_name='Treinamento').set_index('Etiquetas')\n",
    "# excel_teste = pd.read_excel('Joker.xlsx', sheet_name='Teste')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETAPA 2 - Autenticando no Twitter\n",
    "\n",
    "Conta: `@datascience_dudle`\n",
    "\n",
    "\n",
    "Aqui será feita a autenticação no twitter, a partir de um código obtido no próprio site. Apenas o detentor das chaves de acesso da conta no Twitter consegue rodar o cógigo, e por isso ele encontra-se comentado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#leitura do arquivo no formato JSON\n",
    "#with open('auth.pass') as fp:    \n",
    "    \n",
    "    #data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. Não modificar\n",
    "#auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "#auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________\n",
    "\n",
    "### ETAPA 3 - Escolha de um produto e coleta das mensagens\n",
    "\n",
    "No arquivo `Projeto1_Obtenção_dos_tweets.ipynb` foram coletados tweets relacionados ao filme ***Joker***. Ao coletar os tweets com essa keyword, obtivemos 601 tweets para treinamento e 600 para teste. Feita a coleta, esses tweets foram salvos em uma planilha no excel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETAPA 4 - Classificação manual dos tweets\n",
    "\n",
    "Vale ressaltar que o foco desse estudo é analisar o sentimento dos tweets relacionados ao premiado filme ***Joker***.\n",
    "Desta forma, foram previamente estabelecidas 4 categorias para a classificação das mensagens:\n",
    "\n",
    "* `1` - ***Crítica positiva*** – se a mensagem transmitida é uma crítica positiva;\n",
    "* `2` - ***Crítica negativa*** – se a mensagem transmitida é uma crítica negativa;\n",
    "* `3` - ***Irrelevante*** – se a mensagem transmitida estiver no contexto proposto, mas não for relevante para análise;\n",
    "* `4` - ***Reação*** - se a mensagem transmitida trata-se de uma reação ou emoção em relação ao filme ou a uma cena;\n",
    "* `5` - ***Fora do contexto*** - se a mensagem transmitida esta fora do contexto proposto.\n",
    "\n",
    "\n",
    "Estabelecidas as categorias e selecionados os tweets, foi utilizada a base de treinamento, na qual as mensagens foram qualificadas manualmente no excel de acordo com a categoria mais adequada. Conforme mostra a tabela a seguir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Etiquetas</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mortos pelo regime genocida da china 100.000.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@thiago_joker tempos de quarentena, sei lá né ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>se o governador do rio de janeiro candidatar p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@jillajeeva332 @yutheesh0011 @joker_rowdy @pok...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>galera só pra relembrar os filmes da dc de mai...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Treinamento\n",
       "Etiquetas                                                   \n",
       "5          mortos pelo regime genocida da china 100.000.0...\n",
       "5          @thiago_joker tempos de quarentena, sei lá né ...\n",
       "5          se o governador do rio de janeiro candidatar p...\n",
       "5          @jillajeeva332 @yutheesh0011 @joker_rowdy @pok...\n",
       "3          galera só pra relembrar os filmes da dc de mai..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETAPA 5 - Montando o Classificador Naive-Bayes\n",
    "\n",
    "### *Naive Bayes*\n",
    "O algoritmo de *Naive Bayes* é um classificador probabilístico baseado no teorema de Bayes, utilizado no processo de machine learning. O algoritmo supõe que uma característica independe da outra para acontecer, ou seja, mesmo na presença de uma característica particular em uma classe, isso não afeta na probabilidade de qualquer característica ocorrer. O teorema de bayes é escrito da seguinte forma:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/bayes.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ***`P(A)`*** - Probabilidade a priori\n",
    "* ***`P(B)`*** - Probilidade Total\n",
    "* ***`P(A|B)`*** - posteriori\n",
    "* ***`P(B|A)`*** - verossimilhanca\n",
    "\n",
    "\n",
    "Esse método será utilizado no projeto, uma vez que permite calcular a probabilidade de uma mensagem receber diferentes classificações, por exemplo, dada as palavras utilizadas, assumindo que as palavras em um tweet não tem nenhuma relação entre elas.\n",
    "\n",
    "A partir do nosso modelo, poderíamos reescrever o teorema de bayes da seguinte forma:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/bayes1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A variável C é a classe variável que representa a categoria de um tweet, a partir das condições estabelecidas (probabilidade de ocorrência de uma palavra dada as condições). A variável P representa as palavras ocorridas nos tweets.\n",
    "\n",
    "\n",
    "P pode ser:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/bayes2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Substituindo P por cada uma das possíveis palavras, temos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/bayes3.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para implementar esse algoritmo, uma nova tabela deve ser criada com as palavras e suas respectivas frequências relativas em cada uma das categorias. Porém antes disso, deverá ser feita uma limpeza das mensagens, removendo pontuações e caracteres que não convém a análise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-aff0e1514046>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexcel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTreinamento\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Etiquetas'\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   3116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3117\u001b[0m             return self._engine.get_value(s, k,\n\u001b[0;32m-> 3118\u001b[0;31m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[1;32m   3119\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3120\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minferred_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'integer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'boolean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine._get_loc_duplicates\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.index.Int64Engine._maybe_get_bool_indexer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: False"
     ]
    }
   ],
   "source": [
    "excel.Treinamento['Etiquetas'==1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mortos',\n",
       " 'pelo',\n",
       " 'regime',\n",
       " 'genocida',\n",
       " 'da',\n",
       " 'china',\n",
       " '100',\n",
       " '000',\n",
       " '000',\n",
       " 'de',\n",
       " 'pessoas',\n",
       " 'mortos',\n",
       " 'pelo',\n",
       " 'regime',\n",
       " 'genocida',\n",
       " 'do',\n",
       " 'bolsonaro',\n",
       " '0',\n",
       " 'vão',\n",
       " 'pentear',\n",
       " 'macaco',\n",
       " 'esquerdista',\n",
       " 'tem',\n",
       " 'retardo',\n",
       " 'mental',\n",
       " '@thiago_joker',\n",
       " 'tempos',\n",
       " 'de',\n",
       " 'quarentena',\n",
       " 'sei',\n",
       " 'lá',\n",
       " 'né',\n",
       " 'hahahahhahaha',\n",
       " 'se',\n",
       " 'o',\n",
       " 'governador',\n",
       " 'do',\n",
       " 'rio',\n",
       " 'de',\n",
       " 'janeiro',\n",
       " 'candidatar',\n",
       " 'para',\n",
       " 'presidente',\n",
       " 'eu',\n",
       " 'faço',\n",
       " 'campanha',\n",
       " 'até',\n",
       " 'o',\n",
       " 'cara',\n",
       " 'foi',\n",
       " 'o',\n",
       " 'único',\n",
       " 'até',\n",
       " 'agora',\n",
       " 'que',\n",
       " 'detonou',\n",
       " 'ao',\n",
       " 'vivo',\n",
       " 'o',\n",
       " 'presidente',\n",
       " 'que',\n",
       " 'só',\n",
       " 'faz',\n",
       " 'política',\n",
       " 'nesse',\n",
       " 'momento',\n",
       " 'e',\n",
       " 'não',\n",
       " 'resolve',\n",
       " 'nada',\n",
       " '@jillajeeva332',\n",
       " '@yutheesh0011',\n",
       " '@joker_rowdy',\n",
       " '@pokkiri_gvan',\n",
       " '@tsuriya16',\n",
       " '@saranveriyan',\n",
       " '@gmfarook1',\n",
       " '@karthikbigil',\n",
       " '@teamthalapathy1',\n",
       " '@itz_pokkiri7',\n",
       " 'atha',\n",
       " 'maranthuta',\n",
       " 'namba',\n",
       " 'galera',\n",
       " 'só',\n",
       " 'pra',\n",
       " 'relembrar',\n",
       " 'os',\n",
       " 'filmes',\n",
       " 'da',\n",
       " 'dc',\n",
       " 'de',\n",
       " 'maior',\n",
       " 'bilheteria',\n",
       " 'no',\n",
       " 'japão🇯🇵',\n",
       " 'onde',\n",
       " 'estará',\n",
       " 'birdsofprey',\n",
       " 'isso',\n",
       " 'só',\n",
       " 'o',\n",
       " 'tempo',\n",
       " 'dirá',\n",
       " '1',\n",
       " 'joker',\n",
       " '46',\n",
       " '7m',\n",
       " '2',\n",
       " 'constantine',\n",
       " '24',\n",
       " '5m',\n",
       " '3',\n",
       " 'thedarkknightrises',\n",
       " '24',\n",
       " '1m',\n",
       " '4',\n",
       " 'batmanvsuperman',\n",
       " '16',\n",
       " '5m',\n",
       " '5',\n",
       " 'suicidesquad',\n",
       " '15',\n",
       " '6m',\n",
       " '6',\n",
       " 'aquaman',\n",
       " '14',\n",
       " '8m',\n",
       " '7',\n",
       " 'thedarkknight',\n",
       " '14',\n",
       " '5m',\n",
       " '1/2',\n",
       " 'https',\n",
       " '//t',\n",
       " 'co/tzuonluwv7',\n",
       " '@the_lem0s',\n",
       " '@leandro_peroni',\n",
       " 'essa',\n",
       " 'foi',\n",
       " 'uma',\n",
       " 'frase',\n",
       " 'bem',\n",
       " 'do',\n",
       " 'joker',\n",
       " 'antes',\n",
       " 'de',\n",
       " 'matar',\n",
       " 'o',\n",
       " 'murray',\n",
       " '@marqueszero',\n",
       " 'marques',\n",
       " 'sendo',\n",
       " 'realista',\n",
       " 'apesar',\n",
       " 'de',\n",
       " 'não',\n",
       " 'gostar',\n",
       " 'desse',\n",
       " 'cenário',\n",
       " 'vai',\n",
       " 'foder',\n",
       " 'a',\n",
       " 'saúde',\n",
       " 'e',\n",
       " 'vai',\n",
       " 'foder',\n",
       " 'a',\n",
       " 'economia',\n",
       " '19',\n",
       " 'the',\n",
       " 'dark',\n",
       " 'knight',\n",
       " '{assiste',\n",
       " 'toda',\n",
       " 'a',\n",
       " 'trilogia}',\n",
       " '2008',\n",
       " 'sou',\n",
       " 'suspeita',\n",
       " 'pra',\n",
       " 'falar',\n",
       " 'pq',\n",
       " 'amo',\n",
       " 'tudo',\n",
       " 'que',\n",
       " 'envolve',\n",
       " 'o',\n",
       " 'universo',\n",
       " 'do',\n",
       " 'batman',\n",
       " 'mas',\n",
       " 'cara',\n",
       " 'esse',\n",
       " 'é',\n",
       " 'o',\n",
       " 'melhor',\n",
       " 'batman',\n",
       " 'e',\n",
       " 'o',\n",
       " 'melhor',\n",
       " 'joker',\n",
       " 'trailer',\n",
       " 'https',\n",
       " '//t',\n",
       " 'co/uy6ebdhega',\n",
       " '@davialcolumbre',\n",
       " '@senadofederal',\n",
       " '@anastasia',\n",
       " 'você',\n",
       " 'defende',\n",
       " 'quem',\n",
       " 'é',\n",
       " 'responsável',\n",
       " 'por',\n",
       " 'disseminar',\n",
       " 'o',\n",
       " 'mortal',\n",
       " 'viruschines',\n",
       " 'que',\n",
       " 'infectou',\n",
       " 'o',\n",
       " 'mundo',\n",
       " 'e',\n",
       " 'a',\n",
       " 'você',\n",
       " 'mesmo',\n",
       " 'foda',\n",
       " 'se',\n",
       " 'https',\n",
       " '//t',\n",
       " 'co/5mizr70n7j',\n",
       " 'dança',\n",
       " 'da',\n",
       " 'morte',\n",
       " 'https',\n",
       " '//t',\n",
       " 'co/wpmkoltlss',\n",
       " '@isentoes2',\n",
       " 'ele',\n",
       " 'não',\n",
       " 'falou',\n",
       " 'errado',\n",
       " 'ele',\n",
       " 'só',\n",
       " 'falou',\n",
       " 'em',\n",
       " 'mineres',\n",
       " 'rsrs',\n",
       " 'finalmente',\n",
       " 'vou',\n",
       " 'assistir',\n",
       " 'o',\n",
       " 'joker',\n",
       " 'carai',\n",
       " '@nerdboomer',\n",
       " 'joker',\n",
       " 'o',\n",
       " 'ícone',\n",
       " 'dos',\n",
       " 'incels',\n",
       " 'nerds',\n",
       " 'falando',\n",
       " 'a',\n",
       " 'verdade',\n",
       " 'fora',\n",
       " 'da',\n",
       " 'sua',\n",
       " 'matrix',\n",
       " 'isto',\n",
       " 'de',\n",
       " 'estar',\n",
       " 'muito',\n",
       " 'tempo',\n",
       " 'em',\n",
       " 'casa',\n",
       " 'não',\n",
       " 'me',\n",
       " 'esta',\n",
       " 'a',\n",
       " 'fazer',\n",
       " 'bem',\n",
       " 'hoje',\n",
       " 'sonhei',\n",
       " 'que',\n",
       " 'estava',\n",
       " 'a',\n",
       " 'fazer',\n",
       " 'sexo',\n",
       " 'com',\n",
       " 'o',\n",
       " 'joker',\n",
       " 'rt',\n",
       " '@carlosskendrick',\n",
       " 'filha',\n",
       " 'do',\n",
       " 'joker',\n",
       " '😂',\n",
       " '@dracoh8',\n",
       " '@caiquecerq',\n",
       " '@mateuscrz098',\n",
       " '@joker_bsa',\n",
       " '@crisayonara',\n",
       " 'sim',\n",
       " 'pra',\n",
       " 'saírem',\n",
       " 'babu',\n",
       " 'só',\n",
       " 'não',\n",
       " 'saiu',\n",
       " 'na',\n",
       " 'anterior',\n",
       " 'prq',\n",
       " 'foi',\n",
       " 'com',\n",
       " 'o',\n",
       " 'pyong',\n",
       " 'e',\n",
       " 'nessa',\n",
       " 'semana',\n",
       " 'qualquer',\n",
       " 'um',\n",
       " 'que',\n",
       " 'for',\n",
       " 'não',\n",
       " 'sai',\n",
       " 'prq',\n",
       " 'será',\n",
       " 'do',\n",
       " 'daniel',\n",
       " 'se',\n",
       " 'ele',\n",
       " 'não',\n",
       " 'sair',\n",
       " 'no',\n",
       " 'bate',\n",
       " 'e',\n",
       " 'volta',\n",
       " '@zeca1908',\n",
       " 'a',\n",
       " 'gabi',\n",
       " 'vai',\n",
       " 'estar',\n",
       " 'imune',\n",
       " 'a',\n",
       " 'rafa',\n",
       " 'vai',\n",
       " 'imunizar',\n",
       " 'ela',\n",
       " 'com',\n",
       " 'o',\n",
       " 'anjo',\n",
       " 'rt',\n",
       " '@flamengo',\n",
       " 'saudades',\n",
       " '😂🤷\\u200d♂️',\n",
       " '@joaocsoares88',\n",
       " '@thecrepitos',\n",
       " 'estava',\n",
       " 'assistindo',\n",
       " 'ainda',\n",
       " 'a',\n",
       " 'pouco',\n",
       " 'rt',\n",
       " '@drawn_mask',\n",
       " 'estou',\n",
       " 'deveras',\n",
       " 'confuso',\n",
       " 'https',\n",
       " '//t',\n",
       " 'co/p0fkemlfdm',\n",
       " '@juliannevituri',\n",
       " 'louquíssimo',\n",
       " 'os',\n",
       " 'capeto',\n",
       " 'morrendo',\n",
       " 'ces',\n",
       " 'perceberam',\n",
       " 'que',\n",
       " 'no',\n",
       " 'joker',\n",
       " '2019',\n",
       " 'ele',\n",
       " 'ta',\n",
       " 'sempre',\n",
       " 'com',\n",
       " 'a',\n",
       " 'maquiagem',\n",
       " 'do',\n",
       " 'olho',\n",
       " 'esquerdo',\n",
       " 'borrada',\n",
       " 'e',\n",
       " 'dizem',\n",
       " 'que',\n",
       " 'sempre',\n",
       " 'que',\n",
       " 'o',\n",
       " 'choro',\n",
       " 'é',\n",
       " 'de',\n",
       " 'tristeza',\n",
       " 'as',\n",
       " 'lágrimas',\n",
       " 'saem',\n",
       " 'primeiro',\n",
       " 'do',\n",
       " 'olho',\n",
       " 'esquerdo',\n",
       " 'to',\n",
       " 'em',\n",
       " 'shokk',\n",
       " 'com',\n",
       " 'esse',\n",
       " 'filme',\n",
       " 'o',\n",
       " 'meu',\n",
       " 'desejo',\n",
       " 'mais',\n",
       " 'sincero',\n",
       " 'é',\n",
       " 'de',\n",
       " 'que',\n",
       " 'o',\n",
       " 'todd',\n",
       " 'phillips',\n",
       " 'nunca',\n",
       " 'tenha',\n",
       " 'que',\n",
       " 'explicar',\n",
       " 'o',\n",
       " 'final',\n",
       " 'de',\n",
       " 'joker',\n",
       " '@bielzinww',\n",
       " 'passo',\n",
       " 'os',\n",
       " 'personagens',\n",
       " 'de',\n",
       " 'batman',\n",
       " 'a',\n",
       " 'série',\n",
       " 'animada',\n",
       " 'numa',\n",
       " 'versão',\n",
       " 'em',\n",
       " '3d',\n",
       " 'feita',\n",
       " 'pelo',\n",
       " 'diretor',\n",
       " 'de',\n",
       " 'arte',\n",
       " 'de',\n",
       " 'god',\n",
       " 'of',\n",
       " 'war',\n",
       " 'raff',\n",
       " 'grasseti',\n",
       " 'ficou',\n",
       " 'incrível',\n",
       " 'coringa',\n",
       " 'joker',\n",
       " 'harleyquinn',\n",
       " 'arlequina',\n",
       " 'https',\n",
       " '//t',\n",
       " 'co/ggpw5jzila',\n",
       " '@nerdboomer',\n",
       " 'humm',\n",
       " 'esses',\n",
       " 'gays',\n",
       " 'são',\n",
       " 'todos',\n",
       " 'pagos',\n",
       " 'para',\n",
       " 'fingir',\n",
       " 'sofrimento',\n",
       " 'e',\n",
       " 'blá',\n",
       " 'blá',\n",
       " 'blá',\n",
       " 'se',\n",
       " 'tivessem',\n",
       " 'assistido',\n",
       " 'o',\n",
       " 'filme',\n",
       " 'do',\n",
       " 'joker',\n",
       " 'eles',\n",
       " 'teria',\n",
       " 'entendido',\n",
       " 'a',\n",
       " 'verdade',\n",
       " 'de',\n",
       " 'lá',\n",
       " 's0ciedade',\n",
       " 'mas',\n",
       " 'eles',\n",
       " 'nunca',\n",
       " 'me',\n",
       " 'dão',\n",
       " 'atenção',\n",
       " '😡😡😡😭😭😭😭😭nunca',\n",
       " 'dão',\n",
       " 'atenção',\n",
       " 'a',\n",
       " 'mim',\n",
       " 'creverson',\n",
       " 'homem',\n",
       " 'de',\n",
       " '34',\n",
       " 'hetero',\n",
       " 'foda',\n",
       " 'nem',\n",
       " 'passou',\n",
       " 'pela',\n",
       " 'minha',\n",
       " 'cabeça',\n",
       " 'trocar',\n",
       " 'de',\n",
       " 'foto',\n",
       " 'do',\n",
       " 'perfil',\n",
       " 'siga',\n",
       " 'todos',\n",
       " 'que',\n",
       " 'fav',\n",
       " 'e',\n",
       " 'rt',\n",
       " 'esse',\n",
       " 'tuite',\n",
       " 'paz',\n",
       " 'bbb20',\n",
       " 'vida',\n",
       " 'futebol',\n",
       " 'brasileirao2020',\n",
       " 'sdv',\n",
       " 'mundial',\n",
       " 'gremio',\n",
       " 'esporte',\n",
       " 'tmj',\n",
       " 'hanking',\n",
       " 'bom',\n",
       " 'aves',\n",
       " 'joker',\n",
       " 'poker',\n",
       " 'joker',\n",
       " 'é',\n",
       " 'uma',\n",
       " 'obra',\n",
       " 'de',\n",
       " 'arte',\n",
       " 'mesmo',\n",
       " 'nao',\n",
       " 'tem',\n",
       " 'jeito',\n",
       " 'atenção',\n",
       " 'prior',\n",
       " 'incorporou',\n",
       " 'o',\n",
       " 'joker',\n",
       " 'altura',\n",
       " 'ー',\n",
       " '1',\n",
       " '70',\n",
       " 'idade',\n",
       " 'ー17',\n",
       " 'tamanho',\n",
       " 'do',\n",
       " 'pé',\n",
       " 'ー',\n",
       " '40',\n",
       " 'signo',\n",
       " 'ー',\n",
       " 'touro',\n",
       " 'tatuagens',\n",
       " 'ー0',\n",
       " 'piercings',\n",
       " 'ー',\n",
       " '0',\n",
       " 'cor',\n",
       " 'fav',\n",
       " 'ー',\n",
       " 'cinza',\n",
       " 'filme',\n",
       " 'fav',\n",
       " 'ー',\n",
       " 'joker',\n",
       " 'comida',\n",
       " 'fav',\n",
       " '—strogonoff',\n",
       " 'bebida',\n",
       " 'fav',\n",
       " 'ー',\n",
       " 'coca',\n",
       " 'cola',\n",
       " 'série',\n",
       " 'fav',\n",
       " 'ー',\n",
       " 'supernatural',\n",
       " 'time',\n",
       " 'sport',\n",
       " 'real',\n",
       " 'madrid',\n",
       " 'e',\n",
       " 'são',\n",
       " 'paulo',\n",
       " 'https',\n",
       " '//t',\n",
       " 'co/zd0v85icgz',\n",
       " 'genocida',\n",
       " 'sabe',\n",
       " 'o',\n",
       " 'nome',\n",
       " 'disse',\n",
       " 'indignação',\n",
       " 'seletiva',\n",
       " 'https',\n",
       " '//t',\n",
       " 'co/0x8jpryrtu',\n",
       " '@mutantbanditx',\n",
       " 'mas',\n",
       " 'eu',\n",
       " 'ñ',\n",
       " 'quero',\n",
       " 'amizade',\n",
       " 'entre',\n",
       " 'pscipota',\n",
       " 'nível',\n",
       " 'joker',\n",
       " 'e',\n",
       " 'a',\n",
       " 'harley',\n",
       " 'mas',\n",
       " 'tb',\n",
       " 'ñ',\n",
       " 'quero',\n",
       " 'o',\n",
       " 'q',\n",
       " 'a',\n",
       " 'dc',\n",
       " 'fez',\n",
       " '@kevyn_duart7',\n",
       " 'vou',\n",
       " 'pensar',\n",
       " 'no',\n",
       " 'de',\n",
       " 'amanhã',\n",
       " 'ainda',\n",
       " 'kkkj',\n",
       " '@natewithane',\n",
       " 'eu',\n",
       " 'acho',\n",
       " 'que',\n",
       " 'por',\n",
       " 'mais',\n",
       " 'improvável',\n",
       " 'que',\n",
       " 'seja',\n",
       " 'por',\n",
       " 'macho',\n",
       " 'acho',\n",
       " 'que',\n",
       " 'só',\n",
       " 'a',\n",
       " 'punchline',\n",
       " 'esta',\n",
       " 'pois',\n",
       " 'a',\n",
       " 'harley',\n",
       " 'esta',\n",
       " 'tentando',\n",
       " 'matar',\n",
       " 'o',\n",
       " 'coringa',\n",
       " 'e',\n",
       " 'não',\n",
       " 'está',\n",
       " 'brigando',\n",
       " 'com',\n",
       " 'a',\n",
       " 'punch',\n",
       " 'por',\n",
       " 'ele',\n",
       " 'mais',\n",
       " 'a',\n",
       " 'punch',\n",
       " 'eu',\n",
       " 'já',\n",
       " 'não',\n",
       " 'sei',\n",
       " 'pois',\n",
       " 'ela',\n",
       " 'provavelmente',\n",
       " 'está',\n",
       " 'defendendo',\n",
       " 'o',\n",
       " 'joker',\n",
       " '@thwlrs',\n",
       " '@adrieli_s',\n",
       " 'o',\n",
       " 'brasil',\n",
       " 'possui',\n",
       " '23',\n",
       " '102',\n",
       " 'km',\n",
       " 'de',\n",
       " 'fronteiras',\n",
       " 'sendo',\n",
       " '15',\n",
       " '735',\n",
       " 'km',\n",
       " 'terrestres',\n",
       " 'e',\n",
       " '7',\n",
       " '367',\n",
       " 'km',\n",
       " 'marítimas',\n",
       " 'ahahahahhahahahahah',\n",
       " 'de',\n",
       " 'novo',\n",
       " 'seu',\n",
       " 'argumento',\n",
       " 'não',\n",
       " 'deu',\n",
       " 'o',\n",
       " 'que',\n",
       " 'o',\n",
       " 'brasil',\n",
       " 'tem',\n",
       " 'de',\n",
       " 'fronteira',\n",
       " 'a',\n",
       " 'itália',\n",
       " 'não',\n",
       " 'tem',\n",
       " 'de',\n",
       " 'dimensão',\n",
       " 'vendo',\n",
       " 'hobbs',\n",
       " 'and',\n",
       " 'shaw',\n",
       " 'pela',\n",
       " 'milésima',\n",
       " 'vez',\n",
       " 'filme',\n",
       " 'de',\n",
       " 'macho',\n",
       " 'de',\n",
       " 'qualidade',\n",
       " 'o',\n",
       " 'soco',\n",
       " 'no',\n",
       " 'joker',\n",
       " '@santoos__m',\n",
       " 'toma',\n",
       " 'kit',\n",
       " 'island',\n",
       " 'e',\n",
       " 'joker',\n",
       " 'tá',\n",
       " 'imune',\n",
       " 'rt',\n",
       " '@falasdobatima',\n",
       " 'ahnnn',\n",
       " 'eu',\n",
       " 'nao',\n",
       " 'posso',\n",
       " 'fazê',\n",
       " 'mais',\n",
       " 'nada',\n",
       " 'tô',\n",
       " 'ficando',\n",
       " 'velho',\n",
       " 'tô',\n",
       " 'acabado',\n",
       " 'meu',\n",
       " 'pinto',\n",
       " 'não',\n",
       " 'sobe',\n",
       " 'mais',\n",
       " 'eu',\n",
       " 'preciso',\n",
       " 'fazê',\n",
       " 'alguma…',\n",
       " '@odiodobem',\n",
       " '@bolsonarosp',\n",
       " 'esquerda',\n",
       " 'e',\n",
       " 'seu',\n",
       " 'amor',\n",
       " 'ao',\n",
       " 'próximo',\n",
       " 'https',\n",
       " '//t',\n",
       " 'co/xjht3ay9wd',\n",
       " '@ocoringadobem',\n",
       " 'mandetta',\n",
       " 'é',\n",
       " 'outro',\n",
       " 'vendido',\n",
       " 'joker',\n",
       " 'não',\n",
       " 'se',\n",
       " 'salva',\n",
       " 'um',\n",
       " 'olhei',\n",
       " 'joker',\n",
       " 'e',\n",
       " 'cara',\n",
       " 'que',\n",
       " 'filme',\n",
       " 'foda',\n",
       " 'depois',\n",
       " 'de',\n",
       " 'ver',\n",
       " 'joker',\n",
       " 'é',\n",
       " 'a',\n",
       " 'vida',\n",
       " '@eu_joker',\n",
       " '@adrieli_s',\n",
       " 'quando',\n",
       " 'bolsonaro',\n",
       " 'convoca',\n",
       " 'o',\n",
       " 'povo',\n",
       " 'às',\n",
       " 'ruas',\n",
       " 'diz',\n",
       " 'pra',\n",
       " 'continuar',\n",
       " 'indo',\n",
       " 'à',\n",
       " 'missa',\n",
       " 'ao',\n",
       " 'futebol',\n",
       " 'ele',\n",
       " 'está',\n",
       " 'sim',\n",
       " 'sendo',\n",
       " 'irresponsável',\n",
       " 'quando',\n",
       " 'ele',\n",
       " 'com',\n",
       " 'suspeita',\n",
       " 'de',\n",
       " 'contágio',\n",
       " 'e',\n",
       " 'se',\n",
       " 'recusando',\n",
       " 'a',\n",
       " 'mostrar',\n",
       " 'os',\n",
       " 'testes',\n",
       " 'sai',\n",
       " 'às',\n",
       " 'ruas',\n",
       " 'cumprimentando',\n",
       " 'as',\n",
       " 'pessoas',\n",
       " 'que',\n",
       " 'ele',\n",
       " 'chamou',\n",
       " 'ali',\n",
       " 'está',\n",
       " 'errado',\n",
       " 'rt',\n",
       " '@sarfuuu__',\n",
       " 'taroq',\n",
       " 'jamil',\n",
       " 'https',\n",
       " '//t',\n",
       " 'co/4976ohu1in',\n",
       " '@httpsrecess',\n",
       " 'isso',\n",
       " 'é',\n",
       " 'carbo',\n",
       " 'e',\n",
       " 'vitamina',\n",
       " 'vc',\n",
       " 'precisava',\n",
       " 'come',\n",
       " 'alguma',\n",
       " 'proteína',\n",
       " 'peixe',\n",
       " 'bife',\n",
       " 'frango',\n",
       " 'ou',\n",
       " 'ovo',\n",
       " 'mais',\n",
       " 'mal',\n",
       " 'faz',\n",
       " 'não',\n",
       " '@dracoh8',\n",
       " '@caiquecerq',\n",
       " '@mateuscrz098',\n",
       " '@joker_bsa',\n",
       " '@crisayonara',\n",
       " 'parece',\n",
       " 'verídico',\n",
       " 'o',\n",
       " 'joker',\n",
       " 'tinha',\n",
       " 'razão',\n",
       " 'https',\n",
       " '//t',\n",
       " 'co/xzis0hsinv',\n",
       " 'https',\n",
       " '//t',\n",
       " 'co/ikbmbhtvj9',\n",
       " '@pedroconforti',\n",
       " '@rick84261031',\n",
       " '@delucca',\n",
       " '@oatila',\n",
       " 'tenta',\n",
       " 'de',\n",
       " 'novo',\n",
       " 'nobre',\n",
       " 'asno',\n",
       " 'tava',\n",
       " 'procurando',\n",
       " 'o',\n",
       " 'filme',\n",
       " 'do',\n",
       " 'joker',\n",
       " 'pra',\n",
       " 'baixar',\n",
       " 'e',\n",
       " 'assistir',\n",
       " 'com',\n",
       " 'meu',\n",
       " 'pai',\n",
       " 'e',\n",
       " 'não',\n",
       " 'tava',\n",
       " 'achando',\n",
       " 'site',\n",
       " 'takei',\n",
       " 'o',\n",
       " 'fodase',\n",
       " 'e',\n",
       " 'baixei',\n",
       " 'no',\n",
       " 'xvideos',\n",
       " '👍',\n",
       " 'pessoas',\n",
       " 'que',\n",
       " 'ouvem',\n",
       " 'the',\n",
       " 'weeknd',\n",
       " 'tem',\n",
       " 'um',\n",
       " 'lado',\n",
       " 'obscuro',\n",
       " '😫',\n",
       " 'e',\n",
       " 'preferem',\n",
       " 'o',\n",
       " 'joker',\n",
       " 'a',\n",
       " 'parasite',\n",
       " 'porque',\n",
       " 'se',\n",
       " 'identificam',\n",
       " 'se',\n",
       " 'bue',\n",
       " 'com',\n",
       " 'o',\n",
       " 'filme',\n",
       " '😔😔',\n",
       " '@vieiravictorrr',\n",
       " 'booooa',\n",
       " 'jogador',\n",
       " 'ai',\n",
       " 'eu',\n",
       " 'vi',\n",
       " 'mesmo',\n",
       " 'fodaaas',\n",
       " 'rt',\n",
       " '@jafarmsd71',\n",
       " '@nallavanmemes',\n",
       " '@actorvijay',\n",
       " '@kingmakerthala0',\n",
       " '@nkpmuruga2',\n",
       " '@muruganajith46',\n",
       " '@itz_seeni',\n",
       " '@itz_rdx2',\n",
       " '@mrthanimai_v3',\n",
       " '@its_joker_ak_7…',\n",
       " '@ddsaldanha',\n",
       " '@danielzis1',\n",
       " 'o',\n",
       " 'melhor',\n",
       " 'é',\n",
       " 'que',\n",
       " 'la',\n",
       " 'fora',\n",
       " 'ninguém',\n",
       " 'entende',\n",
       " ...]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Juntando todos os tweets da base de treinamento\n",
    "texto_completo = cleanup(' '.join(excel.Treinamento)).split()\n",
    "texto_completo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat(n):\n",
    "    p = cleanup(' '.join(excel[excel.Etiquetas==cat].Treinamento)).split()\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'Etiquetas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-072685b03e24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-e0ad5d7d5130>\u001b[0m in \u001b[0;36mcat\u001b[0;34m(n)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexcel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexcel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEtiquetas\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTreinamento\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   4374\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4375\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4376\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4378\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'Etiquetas'"
     ]
    }
   ],
   "source": [
    "cat(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROJETO 1 - CLASSIFICADOR DE SENTIMENTO DO FILME JOKER\n",
    "__________________________________________________________________________________________________________________\n",
    "\n",
    "### Alunos:\n",
    "\n",
    "Nome: Beatriz Cabral Fernandes \n",
    "\n",
    "Nome: Eduardo Ancona Mateus \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. INTRODU√á√ÉO \n",
    "\n",
    "A proposta desse projeto √© desenvolver um classificador que ir√° analisar como o p√∫blico est√° reagindo ao premiado filme ***Joker***, do diretor *Todd Phillips*. Para isso, ser√° utilizado como m√©todo o famoso algoritmo de Naive-Bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. DESENVOLVIMENTO E METODOLOGIA\n",
    "\n",
    "A fim de simplificar a explica√ß√£o do processo de desenvolvimento do projeto, ele ser√° dividido em X etapas\n",
    "\n",
    "### ETAPA 1 - Preparando o ambiente no Jupyter\n",
    "\n",
    "Nessa etapa, ser√£o baixadas e importadas todas as bibliotecas relevantes para o c√≥digo, bem como implementadas todas as fun√ß√µes a serem utilizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "#Instalando o tweepy\n",
    "!pip install tweepy\n",
    "\n",
    "#Importando as bibliotecas\n",
    "import tweepy\n",
    "import math\n",
    "import os.path\n",
    "import pandas as pd\n",
    "import json\n",
    "from random import shuffle\n",
    "from IPython.display import Image\n",
    "import re\n",
    "\n",
    "#criando funcao de limpeza de caracteres\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Fun√ß√£o de limpeza muito simples que troca alguns sinais b√°sicos por espa√ßos\n",
    "    \"\"\"\n",
    "    #import string\n",
    "    punctuation = '[!-.:?;]' # Note que os sinais [] s√£o delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, ' ', text)\n",
    "    return text_subbed\n",
    "\n",
    "# Fazendo a leitura da planilha de treinamento\n",
    "excel = pd.read_excel('Joker.xlsx', sheet_name='Treinamento').set_index('Etiquetas')\n",
    "# excel_teste = pd.read_excel('Joker.xlsx', sheet_name='Teste')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETAPA 2 - Autenticando no Twitter\n",
    "\n",
    "Conta: `@datascience_dudle`\n",
    "\n",
    "\n",
    "Aqui ser√° feita a autentica√ß√£o no twitter, a partir de um c√≥digo obtido no pr√≥prio site. Apenas o detentor das chaves de acesso da conta no Twitter consegue rodar o c√≥gigo, e por isso ele encontra-se comentado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#leitura do arquivo no formato JSON\n",
    "#with open('auth.pass') as fp:    \n",
    "    \n",
    "    #data = json.load(fp)\n",
    "\n",
    "#Configurando a biblioteca. N√£o modificar\n",
    "#auth = tweepy.OAuthHandler(data['consumer_key'], data['consumer_secret'])\n",
    "#auth.set_access_token(data['access_token'], data['access_token_secret'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________\n",
    "\n",
    "### ETAPA 3 - Escolha de um produto e coleta das mensagens\n",
    "\n",
    "No arquivo `Projeto1_Obten√ß√£o_dos_tweets.ipynb` foram coletados tweets relacionados ao filme ***Joker***. Ao coletar os tweets com essa keyword, obtivemos 601 tweets para treinamento e 600 para teste. Feita a coleta, esses tweets foram salvos em uma planilha no excel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETAPA 4 - Classifica√ß√£o manual dos tweets\n",
    "\n",
    "Vale ressaltar que o foco desse estudo √© analisar o sentimento dos tweets relacionados ao premiado filme ***Joker***.\n",
    "Desta forma, foram previamente estabelecidas 4 categorias para a classifica√ß√£o das mensagens:\n",
    "\n",
    "* `1` - ***Cr√≠tica positiva*** ‚Äì se a mensagem transmitida √© uma cr√≠tica positiva;\n",
    "* `2` - ***Cr√≠tica negativa*** ‚Äì se a mensagem transmitida √© uma cr√≠tica negativa;\n",
    "* `3` - ***Irrelevante*** ‚Äì se a mensagem transmitida estiver no contexto proposto, mas n√£o for relevante para an√°lise;\n",
    "* `4` - ***Rea√ß√£o*** - se a mensagem transmitida trata-se de uma rea√ß√£o ou emo√ß√£o em rela√ß√£o ao filme ou a uma cena;\n",
    "* `5` - ***Fora do contexto*** - se a mensagem transmitida esta fora do contexto proposto.\n",
    "\n",
    "\n",
    "Estabelecidas as categorias e selecionados os tweets, foi utilizada a base de treinamento, na qual as mensagens foram qualificadas manualmente no excel de acordo com a categoria mais adequada. Conforme mostra a tabela a seguir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Etiquetas</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mortos pelo regime genocida da china 100.000.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@thiago_joker tempos de quarentena, sei l√° n√© ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>se o governador do rio de janeiro candidatar p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@jillajeeva332 @yutheesh0011 @joker_rowdy @pok...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>galera s√≥ pra relembrar os filmes da dc de mai...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Treinamento\n",
       "Etiquetas                                                   \n",
       "5          mortos pelo regime genocida da china 100.000.0...\n",
       "5          @thiago_joker tempos de quarentena, sei l√° n√© ...\n",
       "5          se o governador do rio de janeiro candidatar p...\n",
       "5          @jillajeeva332 @yutheesh0011 @joker_rowdy @pok...\n",
       "3          galera s√≥ pra relembrar os filmes da dc de mai..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excel.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETAPA 5 - Montando o Classificador Naive-Bayes\n",
    "\n",
    "### *Naive Bayes*\n",
    "O algoritmo de *Naive Bayes* √© um classificador probabil√≠stico baseado no teorema de Bayes, utilizado no processo de machine learning. O algoritmo sup√µe que uma caracter√≠stica independe da outra para acontecer, ou seja, mesmo na presen√ßa de uma caracter√≠stica particular em uma classe, isso n√£o afeta na probabilidade de qualquer caracter√≠stica ocorrer. O teorema de bayes √© escrito da seguinte forma:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/bayes.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ***`P(A)`*** - Probabilidade a priori\n",
    "* ***`P(B)`*** - Probilidade Total\n",
    "* ***`P(A|B)`*** - posteriori\n",
    "* ***`P(B|A)`*** - verossimilhanca\n",
    "\n",
    "\n",
    "Esse m√©todo ser√° utilizado no projeto, uma vez que permite calcular a probabilidade de uma mensagem receber diferentes classifica√ß√µes, por exemplo, dada as palavras utilizadas, assumindo que as palavras em um tweet n√£o tem nenhuma rela√ß√£o entre elas.\n",
    "\n",
    "A partir do nosso modelo, poder√≠amos reescrever o teorema de bayes da seguinte forma:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/bayes1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A vari√°vel C √© a classe vari√°vel que representa a categoria de um tweet, a partir das condi√ß√µes estabelecidas (probabilidade de ocorr√™ncia de uma palavra dada as condi√ß√µes). A vari√°vel P representa as palavras ocorridas nos tweets.\n",
    "\n",
    "\n",
    "P pode ser:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/bayes2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Substituindo P por cada uma das poss√≠veis palavras, temos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/bayes3.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para implementar esse algoritmo, uma nova tabela deve ser criada com as palavras e suas respectivas frequ√™ncias relativas em cada uma das categorias. Por√©m antes disso, dever√° ser feita uma limpeza das mensagens, removendo pontua√ß√µes e caracteres que n√£o conv√©m a an√°lise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-aff0e1514046>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexcel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTreinamento\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Etiquetas'\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    765\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   3116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3117\u001b[0m             return self._engine.get_value(s, k,\n\u001b[0;32m-> 3118\u001b[0;31m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[1;32m   3119\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3120\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minferred_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'integer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'boolean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine._get_loc_duplicates\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.index.Int64Engine._maybe_get_bool_indexer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: False"
     ]
    }
   ],
   "source": [
    "excel.Treinamento['Etiquetas'==1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mortos',\n",
       " 'pelo',\n",
       " 'regime',\n",
       " 'genocida',\n",
       " 'da',\n",
       " 'china',\n",
       " '100',\n",
       " '000',\n",
       " '000',\n",
       " 'de',\n",
       " 'pessoas',\n",
       " 'mortos',\n",
       " 'pelo',\n",
       " 'regime',\n",
       " 'genocida',\n",
       " 'do',\n",
       " 'bolsonaro',\n",
       " '0',\n",
       " 'v√£o',\n",
       " 'pentear',\n",
       " 'macaco',\n",
       " 'esquerdista',\n",
       " 'tem',\n",
       " 'retardo',\n",
       " 'mental',\n",
       " '@thiago_joker',\n",
       " 'tempos',\n",
       " 'de',\n",
       " 'quarentena',\n",
       " 'sei',\n",
       " 'l√°',\n",
       " 'n√©',\n",
       " 'hahahahhahaha',\n",
       " 'se',\n",
       " 'o',\n",
       " 'governador',\n",
       " 'do',\n",
       " 'rio',\n",
       " 'de',\n",
       " 'janeiro',\n",
       " 'candidatar',\n",
       " 'para',\n",
       " 'presidente',\n",
       " 'eu',\n",
       " 'fa√ßo',\n",
       " 'campanha',\n",
       " 'at√©',\n",
       " 'o',\n",
       " 'cara',\n",
       " 'foi',\n",
       " 'o',\n",
       " '√∫nico',\n",
       " 'at√©',\n",
       " 'agora',\n",
       " 'que',\n",
       " 'detonou',\n",
       " 'ao',\n",
       " 'vivo',\n",
       " 'o',\n",
       " 'presidente',\n",
       " 'que',\n",
       " 's√≥',\n",
       " 'faz',\n",
       " 'pol√≠tica',\n",
       " 'nesse',\n",
       " 'momento',\n",
       " 'e',\n",
       " 'n√£o',\n",
       " 'resolve',\n",
       " 'nada',\n",
       " '@jillajeeva332',\n",
       " '@yutheesh0011',\n",
       " '@joker_rowdy',\n",
       " '@pokkiri_gvan',\n",
       " '@tsuriya16',\n",
       " '@saranveriyan',\n",
       " '@gmfarook1',\n",
       " '@karthikbigil',\n",
       " '@teamthalapathy1',\n",
       " '@itz_pokkiri7',\n",
       " 'atha',\n",
       " 'maranthuta',\n",
       " 'namba',\n",
       " 'galera',\n",
       " 's√≥',\n",
       " 'pra',\n",
       " 'relembrar',\n",
       " 'os',\n",
       " 'filmes',\n",
       " 'da',\n",
       " 'dc',\n",
       " 'de',\n",
       " 'maior',\n",
       " 'bilheteria',\n",
       " 'no',\n",
       " 'jap√£oüáØüáµ',\n",
       " 'onde',\n",
       " 'estar√°',\n",
       " 'birdsofprey',\n",
       " 'isso',\n",
       " 's√≥',\n",
       " 'o',\n",
       " 'tempo',\n",
       " 'dir√°',\n",
       " '1',\n",
       " 'joker',\n",
       " '46',\n",
       " '7m',\n",
       " '2',\n",
       " 'constantine',\n",
       " '24',\n",
       " '5m',\n",
       " '3',\n",
       " 'thedarkknightrises',\n",
       " '24',\n",
       " '1m',\n",
       " '4',\n",
       " 'batmanvsuperman',\n",
       " '16',\n",
       " '5m',\n",
       " '5',\n",
       " 'suicidesquad',\n",
       " '15',\n",
       " '6m',\n",
       " '6',\n",
       " 'aquaman',\n",
       " '14',\n",
       " '8m',\n",
       " '7',\n",
       " 'thedarkknight',\n",
       " '14',\n",
       " '5m',\n",
       " '1/2',\n",
       " 'https',\n",
       " '//t',\n",
       " 'co/tzuonluwv7',\n",
       " '@the_lem0s',\n",
       " '@leandro_peroni',\n",
       " 'essa',\n",
       " 'foi',\n",
       " 'uma',\n",
       " 'frase',\n",
       " 'bem',\n",
       " 'do',\n",
       " 'joker',\n",
       " 'antes',\n",
       " 'de',\n",
       " 'matar',\n",
       " 'o',\n",
       " 'murray',\n",
       " '@marqueszero',\n",
       " 'marques',\n",
       " 'sendo',\n",
       " 'realista',\n",
       " 'apesar',\n",
       " 'de',\n",
       " 'n√£o',\n",
       " 'gostar',\n",
       " 'desse',\n",
       " 'cen√°rio',\n",
       " 'vai',\n",
       " 'foder',\n",
       " 'a',\n",
       " 'sa√∫de',\n",
       " 'e',\n",
       " 'vai',\n",
       " 'foder',\n",
       " 'a',\n",
       " 'economia',\n",
       " '19',\n",
       " 'the',\n",
       " 'dark',\n",
       " 'knight',\n",
       " '{assiste',\n",
       " 'toda',\n",
       " 'a',\n",
       " 'trilogia}',\n",
       " '2008',\n",
       " 'sou',\n",
       " 'suspeita',\n",
       " 'pra',\n",
       " 'falar',\n",
       " 'pq',\n",
       " 'amo',\n",
       " 'tudo',\n",
       " 'que',\n",
       " 'envolve',\n",
       " 'o',\n",
       " 'universo',\n",
       " 'do',\n",
       " 'batman',\n",
       " 'mas',\n",
       " 'cara',\n",
       " 'esse',\n",
       " '√©',\n",
       " 'o',\n",
       " 'melhor',\n",
       " 'batman',\n",
       " 'e',\n",
       " 'o',\n",
       " 'melhor',\n",
       " 'joker',\n",
       " 'trailer',\n",
       " 'https',\n",
       " '//t',\n",
       " 'co/uy6ebdhega',\n",
       " '@davialcolumbre',\n",
       " '@senadofederal',\n",
       " '@anastasia',\n",
       " 'voc√™',\n",
       " 'defende',\n",
       " 'quem',\n",
       " '√©',\n",
       " 'respons√°vel',\n",
       " 'por',\n",
       " 'disseminar',\n",
       " 'o',\n",
       " 'mortal',\n",
       " 'viruschines',\n",
       " 'que',\n",
       " 'infectou',\n",
       " 'o',\n",
       " 'mundo',\n",
       " 'e',\n",
       " 'a',\n",
       " 'voc√™',\n",
       " 'mesmo',\n",
       " 'foda',\n",
       " 'se',\n",
       " 'https',\n",
       " '//t',\n",
       " 'co/5mizr70n7j',\n",
       " 'dan√ßa',\n",
       " 'da',\n",
       " 'morte',\n",
       " 'https',\n",
       " '//t',\n",
       " 'co/wpmkoltlss',\n",
       " '@isentoes2',\n",
       " 'ele',\n",
       " 'n√£o',\n",
       " 'falou',\n",
       " 'errado',\n",
       " 'ele',\n",
       " 's√≥',\n",
       " 'falou',\n",
       " 'em',\n",
       " 'mineres',\n",
       " 'rsrs',\n",
       " 'finalmente',\n",
       " 'vou',\n",
       " 'assistir',\n",
       " 'o',\n",
       " 'joker',\n",
       " 'carai',\n",
       " '@nerdboomer',\n",
       " 'joker',\n",
       " 'o',\n",
       " '√≠cone',\n",
       " 'dos',\n",
       " 'incels',\n",
       " 'nerds',\n",
       " 'falando',\n",
       " 'a',\n",
       " 'verdade',\n",
       " 'fora',\n",
       " 'da',\n",
       " 'sua',\n",
       " 'matrix',\n",
       " 'isto',\n",
       " 'de',\n",
       " 'estar',\n",
       " 'muito',\n",
       " 'tempo',\n",
       " 'em',\n",
       " 'casa',\n",
       " 'n√£o',\n",
       " 'me',\n",
       " 'esta',\n",
       " 'a',\n",
       " 'fazer',\n",
       " 'bem',\n",
       " 'hoje',\n",
       " 'sonhei',\n",
       " 'que',\n",
       " 'estava',\n",
       " 'a',\n",
       " 'fazer',\n",
       " 'sexo',\n",
       " 'com',\n",
       " 'o',\n",
       " 'joker',\n",
       " 'rt',\n",
       " '@carlosskendrick',\n",
       " 'filha',\n",
       " 'do',\n",
       " 'joker',\n",
       " 'üòÇ',\n",
       " '@dracoh8',\n",
       " '@caiquecerq',\n",
       " '@mateuscrz098',\n",
       " '@joker_bsa',\n",
       " '@crisayonara',\n",
       " 'sim',\n",
       " 'pra',\n",
       " 'sa√≠rem',\n",
       " 'babu',\n",
       " 's√≥',\n",
       " 'n√£o',\n",
       " 'saiu',\n",
       " 'na',\n",
       " 'anterior',\n",
       " 'prq',\n",
       " 'foi',\n",
       " 'com',\n",
       " 'o',\n",
       " 'pyong',\n",
       " 'e',\n",
       " 'nessa',\n",
       " 'semana',\n",
       " 'qualquer',\n",
       " 'um',\n",
       " 'que',\n",
       " 'for',\n",
       " 'n√£o',\n",
       " 'sai',\n",
       " 'prq',\n",
       " 'ser√°',\n",
       " 'do',\n",
       " 'daniel',\n",
       " 'se',\n",
       " 'ele',\n",
       " 'n√£o',\n",
       " 'sair',\n",
       " 'no',\n",
       " 'bate',\n",
       " 'e',\n",
       " 'volta',\n",
       " '@zeca1908',\n",
       " 'a',\n",
       " 'gabi',\n",
       " 'vai',\n",
       " 'estar',\n",
       " 'imune',\n",
       " 'a',\n",
       " 'rafa',\n",
       " 'vai',\n",
       " 'imunizar',\n",
       " 'ela',\n",
       " 'com',\n",
       " 'o',\n",
       " 'anjo',\n",
       " 'rt',\n",
       " '@flamengo',\n",
       " 'saudades',\n",
       " 'üòÇü§∑\\u200d‚ôÇÔ∏è',\n",
       " '@joaocsoares88',\n",
       " '@thecrepitos',\n",
       " 'estava',\n",
       " 'assistindo',\n",
       " 'ainda',\n",
       " 'a',\n",
       " 'pouco',\n",
       " 'rt',\n",
       " '@drawn_mask',\n",
       " 'estou',\n",
       " 'deveras',\n",
       " 'confuso',\n",
       " 'https',\n",
       " '//t',\n",
       " 'co/p0fkemlfdm',\n",
       " '@juliannevituri',\n",
       " 'louqu√≠ssimo',\n",
       " 'os',\n",
       " 'capeto',\n",
       " 'morrendo',\n",
       " 'ces',\n",
       " 'perceberam',\n",
       " 'que',\n",
       " 'no',\n",
       " 'joker',\n",
       " '2019',\n",
       " 'ele',\n",
       " 'ta',\n",
       " 'sempre',\n",
       " 'com',\n",
       " 'a',\n",
       " 'maquiagem',\n",
       " 'do',\n",
       " 'olho',\n",
       " 'esquerdo',\n",
       " 'borrada',\n",
       " 'e',\n",
       " 'dizem',\n",
       " 'que',\n",
       " 'sempre',\n",
       " 'que',\n",
       " 'o',\n",
       " 'choro',\n",
       " '√©',\n",
       " 'de',\n",
       " 'tristeza',\n",
       " 'as',\n",
       " 'l√°grimas',\n",
       " 'saem',\n",
       " 'primeiro',\n",
       " 'do',\n",
       " 'olho',\n",
       " 'esquerdo',\n",
       " 'to',\n",
       " 'em',\n",
       " 'shokk',\n",
       " 'com',\n",
       " 'esse',\n",
       " 'filme',\n",
       " 'o',\n",
       " 'meu',\n",
       " 'desejo',\n",
       " 'mais',\n",
       " 'sincero',\n",
       " '√©',\n",
       " 'de',\n",
       " 'que',\n",
       " 'o',\n",
       " 'todd',\n",
       " 'phillips',\n",
       " 'nunca',\n",
       " 'tenha',\n",
       " 'que',\n",
       " 'explicar',\n",
       " 'o',\n",
       " 'final',\n",
       " 'de',\n",
       " 'joker',\n",
       " '@bielzinww',\n",
       " 'passo',\n",
       " 'os',\n",
       " 'personagens',\n",
       " 'de',\n",
       " 'batman',\n",
       " 'a',\n",
       " 's√©rie',\n",
       " 'animada',\n",
       " 'numa',\n",
       " 'vers√£o',\n",
       " 'em',\n",
       " '3d',\n",
       " 'feita',\n",
       " 'pelo',\n",
       " 'diretor',\n",
       " 'de',\n",
       " 'arte',\n",
       " 'de',\n",
       " 'god',\n",
       " 'of',\n",
       " 'war',\n",
       " 'raff',\n",
       " 'grasseti',\n",
       " 'ficou',\n",
       " 'incr√≠vel',\n",
       " 'coringa',\n",
       " 'joker',\n",
       " 'harleyquinn',\n",
       " 'arlequina',\n",
       " 'https',\n",
       " '//t',\n",
       " 'co/ggpw5jzila',\n",
       " '@nerdboomer',\n",
       " 'humm',\n",
       " 'esses',\n",
       " 'gays',\n",
       " 's√£o',\n",
       " 'todos',\n",
       " 'pagos',\n",
       " 'para',\n",
       " 'fingir',\n",
       " 'sofrimento',\n",
       " 'e',\n",
       " 'bl√°',\n",
       " 'bl√°',\n",
       " 'bl√°',\n",
       " 'se',\n",
       " 'tivessem',\n",
       " 'assistido',\n",
       " 'o',\n",
       " 'filme',\n",
       " 'do',\n",
       " 'joker',\n",
       " 'eles',\n",
       " 'teria',\n",
       " 'entendido',\n",
       " 'a',\n",
       " 'verdade',\n",
       " 'de',\n",
       " 'l√°',\n",
       " 's0ciedade',\n",
       " 'mas',\n",
       " 'eles',\n",
       " 'nunca',\n",
       " 'me',\n",
       " 'd√£o',\n",
       " 'aten√ß√£o',\n",
       " 'üò°üò°üò°üò≠üò≠üò≠üò≠üò≠nunca',\n",
       " 'd√£o',\n",
       " 'aten√ß√£o',\n",
       " 'a',\n",
       " 'mim',\n",
       " 'creverson',\n",
       " 'homem',\n",
       " 'de',\n",
       " '34',\n",
       " 'hetero',\n",
       " 'foda',\n",
       " 'nem',\n",
       " 'passou',\n",
       " 'pela',\n",
       " 'minha',\n",
       " 'cabe√ßa',\n",
       " 'trocar',\n",
       " 'de',\n",
       " 'foto',\n",
       " 'do',\n",
       " 'perfil',\n",
       " 'siga',\n",
       " 'todos',\n",
       " 'que',\n",
       " 'fav',\n",
       " 'e',\n",
       " 'rt',\n",
       " 'esse',\n",
       " 'tuite',\n",
       " 'paz',\n",
       " 'bbb20',\n",
       " 'vida',\n",
       " 'futebol',\n",
       " 'brasileirao2020',\n",
       " 'sdv',\n",
       " 'mundial',\n",
       " 'gremio',\n",
       " 'esporte',\n",
       " 'tmj',\n",
       " 'hanking',\n",
       " 'bom',\n",
       " 'aves',\n",
       " 'joker',\n",
       " 'poker',\n",
       " 'joker',\n",
       " '√©',\n",
       " 'uma',\n",
       " 'obra',\n",
       " 'de',\n",
       " 'arte',\n",
       " 'mesmo',\n",
       " 'nao',\n",
       " 'tem',\n",
       " 'jeito',\n",
       " 'aten√ß√£o',\n",
       " 'prior',\n",
       " 'incorporou',\n",
       " 'o',\n",
       " 'joker',\n",
       " 'altura',\n",
       " '„Éº',\n",
       " '1',\n",
       " '70',\n",
       " 'idade',\n",
       " '„Éº17',\n",
       " 'tamanho',\n",
       " 'do',\n",
       " 'p√©',\n",
       " '„Éº',\n",
       " '40',\n",
       " 'signo',\n",
       " '„Éº',\n",
       " 'touro',\n",
       " 'tatuagens',\n",
       " '„Éº0',\n",
       " 'piercings',\n",
       " '„Éº',\n",
       " '0',\n",
       " 'cor',\n",
       " 'fav',\n",
       " '„Éº',\n",
       " 'cinza',\n",
       " 'filme',\n",
       " 'fav',\n",
       " '„Éº',\n",
       " 'joker',\n",
       " 'comida',\n",
       " 'fav',\n",
       " '‚Äîstrogonoff',\n",
       " 'bebida',\n",
       " 'fav',\n",
       " '„Éº',\n",
       " 'coca',\n",
       " 'cola',\n",
       " 's√©rie',\n",
       " 'fav',\n",
       " '„Éº',\n",
       " 'supernatural',\n",
       " 'time',\n",
       " 'sport',\n",
       " 'real',\n",
       " 'madrid',\n",
       " 'e',\n",
       " 's√£o',\n",
       " 'paulo',\n",
       " 'https',\n",
       " '//t',\n",
       " 'co/zd0v85icgz',\n",
       " 'genocida',\n",
       " 'sabe',\n",
       " 'o',\n",
       " 'nome',\n",
       " 'disse',\n",
       " 'indigna√ß√£o',\n",
       " 'seletiva',\n",
       " 'https',\n",
       " '//t',\n",
       " 'co/0x8jpryrtu',\n",
       " '@mutantbanditx',\n",
       " 'mas',\n",
       " 'eu',\n",
       " '√±',\n",
       " 'quero',\n",
       " 'amizade',\n",
       " 'entre',\n",
       " 'pscipota',\n",
       " 'n√≠vel',\n",
       " 'joker',\n",
       " 'e',\n",
       " 'a',\n",
       " 'harley',\n",
       " 'mas',\n",
       " 'tb',\n",
       " '√±',\n",
       " 'quero',\n",
       " 'o',\n",
       " 'q',\n",
       " 'a',\n",
       " 'dc',\n",
       " 'fez',\n",
       " '@kevyn_duart7',\n",
       " 'vou',\n",
       " 'pensar',\n",
       " 'no',\n",
       " 'de',\n",
       " 'amanh√£',\n",
       " 'ainda',\n",
       " 'kkkj',\n",
       " '@natewithane',\n",
       " 'eu',\n",
       " 'acho',\n",
       " 'que',\n",
       " 'por',\n",
       " 'mais',\n",
       " 'improv√°vel',\n",
       " 'que',\n",
       " 'seja',\n",
       " 'por',\n",
       " 'macho',\n",
       " 'acho',\n",
       " 'que',\n",
       " 's√≥',\n",
       " 'a',\n",
       " 'punchline',\n",
       " 'esta',\n",
       " 'pois',\n",
       " 'a',\n",
       " 'harley',\n",
       " 'esta',\n",
       " 'tentando',\n",
       " 'matar',\n",
       " 'o',\n",
       " 'coringa',\n",
       " 'e',\n",
       " 'n√£o',\n",
       " 'est√°',\n",
       " 'brigando',\n",
       " 'com',\n",
       " 'a',\n",
       " 'punch',\n",
       " 'por',\n",
       " 'ele',\n",
       " 'mais',\n",
       " 'a',\n",
       " 'punch',\n",
       " 'eu',\n",
       " 'j√°',\n",
       " 'n√£o',\n",
       " 'sei',\n",
       " 'pois',\n",
       " 'ela',\n",
       " 'provavelmente',\n",
       " 'est√°',\n",
       " 'defendendo',\n",
       " 'o',\n",
       " 'joker',\n",
       " '@thwlrs',\n",
       " '@adrieli_s',\n",
       " 'o',\n",
       " 'brasil',\n",
       " 'possui',\n",
       " '23',\n",
       " '102',\n",
       " 'km',\n",
       " 'de',\n",
       " 'fronteiras',\n",
       " 'sendo',\n",
       " '15',\n",
       " '735',\n",
       " 'km',\n",
       " 'terrestres',\n",
       " 'e',\n",
       " '7',\n",
       " '367',\n",
       " 'km',\n",
       " 'mar√≠timas',\n",
       " 'ahahahahhahahahahah',\n",
       " 'de',\n",
       " 'novo',\n",
       " 'seu',\n",
       " 'argumento',\n",
       " 'n√£o',\n",
       " 'deu',\n",
       " 'o',\n",
       " 'que',\n",
       " 'o',\n",
       " 'brasil',\n",
       " 'tem',\n",
       " 'de',\n",
       " 'fronteira',\n",
       " 'a',\n",
       " 'it√°lia',\n",
       " 'n√£o',\n",
       " 'tem',\n",
       " 'de',\n",
       " 'dimens√£o',\n",
       " 'vendo',\n",
       " 'hobbs',\n",
       " 'and',\n",
       " 'shaw',\n",
       " 'pela',\n",
       " 'mil√©sima',\n",
       " 'vez',\n",
       " 'filme',\n",
       " 'de',\n",
       " 'macho',\n",
       " 'de',\n",
       " 'qualidade',\n",
       " 'o',\n",
       " 'soco',\n",
       " 'no',\n",
       " 'joker',\n",
       " '@santoos__m',\n",
       " 'toma',\n",
       " 'kit',\n",
       " 'island',\n",
       " 'e',\n",
       " 'joker',\n",
       " 't√°',\n",
       " 'imune',\n",
       " 'rt',\n",
       " '@falasdobatima',\n",
       " 'ahnnn',\n",
       " 'eu',\n",
       " 'nao',\n",
       " 'posso',\n",
       " 'faz√™',\n",
       " 'mais',\n",
       " 'nada',\n",
       " 't√¥',\n",
       " 'ficando',\n",
       " 'velho',\n",
       " 't√¥',\n",
       " 'acabado',\n",
       " 'meu',\n",
       " 'pinto',\n",
       " 'n√£o',\n",
       " 'sobe',\n",
       " 'mais',\n",
       " 'eu',\n",
       " 'preciso',\n",
       " 'faz√™',\n",
       " 'alguma‚Ä¶',\n",
       " '@odiodobem',\n",
       " '@bolsonarosp',\n",
       " 'esquerda',\n",
       " 'e',\n",
       " 'seu',\n",
       " 'amor',\n",
       " 'ao',\n",
       " 'pr√≥ximo',\n",
       " 'https',\n",
       " '//t',\n",
       " 'co/xjht3ay9wd',\n",
       " '@ocoringadobem',\n",
       " 'mandetta',\n",
       " '√©',\n",
       " 'outro',\n",
       " 'vendido',\n",
       " 'joker',\n",
       " 'n√£o',\n",
       " 'se',\n",
       " 'salva',\n",
       " 'um',\n",
       " 'olhei',\n",
       " 'joker',\n",
       " 'e',\n",
       " 'cara',\n",
       " 'que',\n",
       " 'filme',\n",
       " 'foda',\n",
       " 'depois',\n",
       " 'de',\n",
       " 'ver',\n",
       " 'joker',\n",
       " '√©',\n",
       " 'a',\n",
       " 'vida',\n",
       " '@eu_joker',\n",
       " '@adrieli_s',\n",
       " 'quando',\n",
       " 'bolsonaro',\n",
       " 'convoca',\n",
       " 'o',\n",
       " 'povo',\n",
       " '√†s',\n",
       " 'ruas',\n",
       " 'diz',\n",
       " 'pra',\n",
       " 'continuar',\n",
       " 'indo',\n",
       " '√†',\n",
       " 'missa',\n",
       " 'ao',\n",
       " 'futebol',\n",
       " 'ele',\n",
       " 'est√°',\n",
       " 'sim',\n",
       " 'sendo',\n",
       " 'irrespons√°vel',\n",
       " 'quando',\n",
       " 'ele',\n",
       " 'com',\n",
       " 'suspeita',\n",
       " 'de',\n",
       " 'cont√°gio',\n",
       " 'e',\n",
       " 'se',\n",
       " 'recusando',\n",
       " 'a',\n",
       " 'mostrar',\n",
       " 'os',\n",
       " 'testes',\n",
       " 'sai',\n",
       " '√†s',\n",
       " 'ruas',\n",
       " 'cumprimentando',\n",
       " 'as',\n",
       " 'pessoas',\n",
       " 'que',\n",
       " 'ele',\n",
       " 'chamou',\n",
       " 'ali',\n",
       " 'est√°',\n",
       " 'errado',\n",
       " 'rt',\n",
       " '@sarfuuu__',\n",
       " 'taroq',\n",
       " 'jamil',\n",
       " 'https',\n",
       " '//t',\n",
       " 'co/4976ohu1in',\n",
       " '@httpsrecess',\n",
       " 'isso',\n",
       " '√©',\n",
       " 'carbo',\n",
       " 'e',\n",
       " 'vitamina',\n",
       " 'vc',\n",
       " 'precisava',\n",
       " 'come',\n",
       " 'alguma',\n",
       " 'prote√≠na',\n",
       " 'peixe',\n",
       " 'bife',\n",
       " 'frango',\n",
       " 'ou',\n",
       " 'ovo',\n",
       " 'mais',\n",
       " 'mal',\n",
       " 'faz',\n",
       " 'n√£o',\n",
       " '@dracoh8',\n",
       " '@caiquecerq',\n",
       " '@mateuscrz098',\n",
       " '@joker_bsa',\n",
       " '@crisayonara',\n",
       " 'parece',\n",
       " 'ver√≠dico',\n",
       " 'o',\n",
       " 'joker',\n",
       " 'tinha',\n",
       " 'raz√£o',\n",
       " 'https',\n",
       " '//t',\n",
       " 'co/xzis0hsinv',\n",
       " 'https',\n",
       " '//t',\n",
       " 'co/ikbmbhtvj9',\n",
       " '@pedroconforti',\n",
       " '@rick84261031',\n",
       " '@delucca',\n",
       " '@oatila',\n",
       " 'tenta',\n",
       " 'de',\n",
       " 'novo',\n",
       " 'nobre',\n",
       " 'asno',\n",
       " 'tava',\n",
       " 'procurando',\n",
       " 'o',\n",
       " 'filme',\n",
       " 'do',\n",
       " 'joker',\n",
       " 'pra',\n",
       " 'baixar',\n",
       " 'e',\n",
       " 'assistir',\n",
       " 'com',\n",
       " 'meu',\n",
       " 'pai',\n",
       " 'e',\n",
       " 'n√£o',\n",
       " 'tava',\n",
       " 'achando',\n",
       " 'site',\n",
       " 'takei',\n",
       " 'o',\n",
       " 'fodase',\n",
       " 'e',\n",
       " 'baixei',\n",
       " 'no',\n",
       " 'xvideos',\n",
       " 'üëç',\n",
       " 'pessoas',\n",
       " 'que',\n",
       " 'ouvem',\n",
       " 'the',\n",
       " 'weeknd',\n",
       " 'tem',\n",
       " 'um',\n",
       " 'lado',\n",
       " 'obscuro',\n",
       " 'üò´',\n",
       " 'e',\n",
       " 'preferem',\n",
       " 'o',\n",
       " 'joker',\n",
       " 'a',\n",
       " 'parasite',\n",
       " 'porque',\n",
       " 'se',\n",
       " 'identificam',\n",
       " 'se',\n",
       " 'bue',\n",
       " 'com',\n",
       " 'o',\n",
       " 'filme',\n",
       " 'üòîüòî',\n",
       " '@vieiravictorrr',\n",
       " 'booooa',\n",
       " 'jogador',\n",
       " 'ai',\n",
       " 'eu',\n",
       " 'vi',\n",
       " 'mesmo',\n",
       " 'fodaaas',\n",
       " 'rt',\n",
       " '@jafarmsd71',\n",
       " '@nallavanmemes',\n",
       " '@actorvijay',\n",
       " '@kingmakerthala0',\n",
       " '@nkpmuruga2',\n",
       " '@muruganajith46',\n",
       " '@itz_seeni',\n",
       " '@itz_rdx2',\n",
       " '@mrthanimai_v3',\n",
       " '@its_joker_ak_7‚Ä¶',\n",
       " '@ddsaldanha',\n",
       " '@danielzis1',\n",
       " 'o',\n",
       " 'melhor',\n",
       " '√©',\n",
       " 'que',\n",
       " 'la',\n",
       " 'fora',\n",
       " 'ningu√©m',\n",
       " 'entende',\n",
       " ...]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Juntando todos os tweets da base de treinamento\n",
    "texto_completo = cleanup(' '.join(excel.Treinamento)).split()\n",
    "texto_completo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat(n):\n",
    "    p = cleanup(' '.join(excel[excel.Etiquetas==cat].Treinamento)).split()\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'Etiquetas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-072685b03e24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-e0ad5d7d5130>\u001b[0m in \u001b[0;36mcat\u001b[0;34m(n)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexcel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexcel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEtiquetas\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTreinamento\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   4374\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4375\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4376\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4378\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'Etiquetas'"
     ]
    }
   ],
   "source": [
    "cat(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
